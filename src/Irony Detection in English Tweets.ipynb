{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Irony Detection in English \n",
    "\n",
    "#### The goal of this project consists in training a model capable of performing the task of classificating a tweet in English as ironic or non ironic.\n",
    "\n",
    "Using different classification techniques we intend to find the one that performs better using as training data a data set with around 4000 tweets of different types.\n",
    "\n",
    "This project was made by 3 students as part of the Artificial Intelligence course at FEUP. You are free to use the code for any purpose, but beware that this is just an academia project in an introductory course to Artificial Intelligence.\n",
    "\n",
    "Libraries Used: \n",
    "* Pandas\n",
    "* Numpy\n",
    "* Scikit-learn\n",
    "* Matplotlib\n",
    "* nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Datasets:\n",
    "\n",
    "The data sets for this project are not owned by our group, they are supplied by SemEval competition and are free to use for academic purposes only outside of the competition.\n",
    "\n",
    "There are two data sets available, one marked for train and the other for testing. Originally they were in .txt format, but in order to simplify the work of the pandas library, we manually converted those files to .csv\n",
    "\n",
    "**SemEval organization themselves already provide a division of the dataset in two subsets, a test dataset and a train dataset.**\n",
    "\n",
    "This division is useful for the final evaluation of our work. Since the competition was in 2018, the ranking of the participants for that dataset is already public. This way we are able to keep track of which place we could score in that professional competition\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](../assets/ranking.png)\n",
    "##### Fig1: Ranking of the SemEval competition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Problem with word delimeter\n",
    "\n",
    "Pandas is a library perfect for the job of reading data from a file, since it setup automaticaly the capability of seeing that data in a formatted organized way.\n",
    "\n",
    "Pandas has specific functions to read from different formats. The datasets are originally in .txt format, a conversion for either JSON or CSV, formats accepted by Pandas needed to be done. 4000 tweets in JSON would turn the data file really dense in information.\n",
    "Since we are dealing with just 2 attributes, it is pointless to make our life harder in this step. \n",
    "\n",
    "We chosed .csv format to represent the data\n",
    "\n",
    "CSV files dealing with text rise other problem, the fact that people use comma in their texts, pandas. So we introduce other delimiter,'\\t', so we are able to do the task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, HTML\n",
    "import pandas\n",
    "import numpy\n",
    "\n",
    "train_data=pandas.read_csv('data/train.csv',  delimiter = '\\t', quoting = 3, encoding=\"utf-8\")\n",
    "test_data=pandas.read_csv('data/test-labeled.csv', delimiter = '\\t', quoting = 3, encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Sweet United Nations video. Just in time for C...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>@mrdahl87 We are rumored to have talked to Erv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Hey there! Nice to see you Minnesota/ND Winter...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>3 episodes left I'm dying over here</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>\"I can't breathe!\" was chosen as the most nota...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                              tweet\n",
       "0      1  Sweet United Nations video. Just in time for C...\n",
       "1      1  @mrdahl87 We are rumored to have talked to Erv...\n",
       "2      1  Hey there! Nice to see you Minnesota/ND Winter...\n",
       "3      0                3 episodes left I'm dying over here\n",
       "4      1  \"I can't breathe!\" was chosen as the most nota..."
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>@Callisto1947 Can U Help?||More conservatives ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Just walked in to #Starbucks and asked for a \"...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>#NOT GONNA WIN http://t.co/Mc9ebqjAqj</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>@mickymantell He is exactly that sort of perso...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>So much #sarcasm at work mate 10/10 #boring 10...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                              tweet\n",
       "0      0  @Callisto1947 Can U Help?||More conservatives ...\n",
       "1      1  Just walked in to #Starbucks and asked for a \"...\n",
       "2      0              #NOT GONNA WIN http://t.co/Mc9ebqjAqj\n",
       "3      0  @mickymantell He is exactly that sort of perso...\n",
       "4      1  So much #sarcasm at work mate 10/10 #boring 10..."
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analising the datasets\n",
    "\n",
    "Some initial considerations should be done in order to ensure the quality of the data. The data provided doesn't contain blank fields. \n",
    "\n",
    "Testing proprelly the existance of duplicates in the datasets would require knowledge outside the scope of the course, so we assume that there aren't duplicate data in the dataset.\n",
    "\n",
    "\n",
    "**One very important consideration regarding the data is the possibility of the dataset being unbalanced** With both of our data sets loaded, we can use **Matplotlib** to determine if that consideration holds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAEVCAYAAAAM3jVmAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAAZKUlEQVR4nO3de7xdZX3n8c+3ieAFIiBHCkkwkQY7gbGhnEZaBoullYtV0I4axuFicQIMvMQptID2NdB5NR3GitoURWNBwHIxigpWsCJVGEcUTzASbpEgwRyShoPcokA04Tt/7Ofg4rDPbZ+THcjzfb9e+3XW/q1nrefZJzvfs86z1tlLtomIiDr8xtYeQEREdE9CPyKiIgn9iIiKJPQjIiqS0I+IqEhCPyKiIgn9GDNJ10s6bpL2dYmkv52Mfb2YSPq2pPeV5fdI+sYk7vtOSQeX5XMl/fMk7vuDkv5psvYXW09Cfxsn6eeNxzOSnmo8f8949mX7cNuXbqmxDqcZlF3ud7WkP95S+7d9ue03j2EcY/oBaXsf29+e6LgkHSypf8i+/8521/8NYvJN3doDiC3L9g6Dy5JWA++z/c2h7SRNtb2pm2OLyZF/uxiPHOlXavBoTtKZkv4d+KyknSX9i6QBSY+W5RmNbZpTE8dL+o6kj5S290s6fIT+9pN0m6QNkj4PvLSxbth+JS0CDgIuKL+dXFDq/yBpjaQnJC2TdNAIfR8h6a7S94OSzmis+1NJyyU9Jum7kl5f6p8D9gS+Wvr9qw6/z38i6R5Jj5exq7HueEnfKcuS9DFJD5W2t0vaV9JC4D3AX5VxfLW0X13+7W4HfiFpapvfTF4q6fPldd8m6XcafVvSbzWeXyLpbyW9Arge2KPxG+EeQ6eLJL2tTCc9Vt4X/6GxbrWkM8preLyM4dl/79i6Evp1+01gF+A1wEJa74fPlud7Ak8BF4yw/RuAlcCuwIeBiyRpaCNJ2wFfAT5X+vsC8GeNJsP2a/tDwP8FTrW9g+1TyzY/AOaV/V0BfGGEYLkIONH2jsC+wL+Vcf0ucDFwIvAq4NPAtZK2t30M8FPgraXfD4/wfWhL0q7A1cBf0/oe3QccOEzzNwNvBPYGdgLeDfzM9hLgcuDDZRxvbWxzNPAWYKdhjvSPpPW9HvwefUXSS0Yas+1fAIcDa0t/O9heO+R17Q1cCXwA6AGuo/XDcbtGs3cBhwGzgdcDx4/Ub3RPQr9uzwDn2N5o+ynbP7N9te0nbW8AFgF/OML2D9j+jO3NwKXA7sBubdodALwE+LjtX9n+Iq3QBqCDfrH9z2W7TbbPB7YHXjdM818BcyVNs/2o7dtK/b8Bn7b9fduby/mKjWW8k+EI4C7bX7T9K+DjwL+PMMYdgd8GZPtu2+tG2f9i22tsPzXM+mWNvj9K67eryXht7wa+ZvuGsu+PAC8D/mDI2NbafgT4Kq0f0PECkNCv24DtpwefSHq5pE9LekDSE8DNwE6Spgyz/bMBZvvJsrhDm3Z7AA/6uZ/u98AE+kXS6ZLuLtMHjwGvpHU03c6f0QrgByTdJOn3S/01wOlliuKxsp+ZZbyjUutqppFOiu8BrBl8Ul7/mjbtsP1vtH67+QSwXtISSdNGGULbfbVbb/sZoJ8xvrZR7EHj36/sew0wvdGm+cPtSdq/L2IrSOjXbehHrJ5O62j5Dban0ZpugMY8dIfWAdOHTP3sOY5+nzPOMn9/Jq0phJ1t7wQ8Ptw4bf/A9pHAq2lNMy0tq9YAi2zv1Hi83PaV7fpts9/DG1Mglw/zumc2xq3m8zb7W2x7f2AfWtM8fznKOEb7iNxm378BzAAGp2qeBF7eaPub49jvWlo/MAf3Pfi6Hhxlu3gBSOhH04605tMfk7QLcM4k7fcWYBPw/nLC8R3A/HH0ux547ZD2m4ABYKqk/wm0PSqWtJ1a18O/skxFPAFsLqs/A5wk6Q3lROorJL1F0o7D9DteXwP2kfQOSVOB9/PccG2O8/fKOF4C/AJ4ujHOTsexf6PvD9CauvpeWbcc+C+Spkg6jOdOp60HXiXplcPsdynwFkmHlPGeXvb93Q7GGF2W0I+mj9Oam32YVjh8fTJ2avuXwDtoncx7lNac8JfG0e8/AP9ZrSt7FgP/SusKkx/TmmZ4mpGnOo4BVpepo5OA/1rG1UdrXv+CMq5VPPeE4/8G/rpM/ZzBONl+GHgncB7wM2AO8P+GaT6N1g+hR8tr+hmtuXJonYieW8bxlXEM4Rpa3+tHaX0P3lF+8AGcBrwVeIzW1UHP7tf2PbRO1P6k9PmcKSHbK2l9D/+R1r/ZW2md8P7lOMYWW4lyE5WIiHrkSD8ioiIJ/YiIiiT0IyIqktCPiKhIQj8ioiIJ/YiIiiT0IyIqktCPiKhIQj8ioiIJ/YiIiiT0IyIqktCPiKhIQj8ioiIJ/YiIiiT0IyIqktCPiKjIqKEvaaakb5WbUN8p6bRS30XSDZLuLV93bmxztqRVklZKOrRR31/SirJu8ZB7pkZExBY26p2zJO0O7G77tnLv0GXAUbRuK/eI7fMknUXrBtVnSppL61Zr84E9gG8Ce9veLOlWWrdp+x5wHbDY9vUj9b/rrrt61qxZE3iJERH1WbZs2cO2e4bWp462oe11wLqyvEHS3cB04Ejg4NLsUuDbwJmlfpXtjcD9klYB8yWtBqbZvgVA0mW0fniMGPqzZs2ir69v9FcYERHPkvRAu/q45vQlzQL2A74P7FZ+IAz+YHh1aTad596kur/UppflofV2/SyU1Cepb2BgYDxDjIiIEYw59CXtAFwNfMD2EyM1bVPzCPXnF+0ltntt9/b0PO+3k4iI6NCYQl/SS2gF/uW2v1TK68t8/+C8/0Ol3g/MbGw+A1hb6jPa1CMiokvGcvWOgIuAu21/tLHqWuC4snwccE2jvkDS9pJmA3OAW8sU0AZJB5R9HtvYJiIiumDUE7nAgcAxwApJy0vtg8B5wFJJJwA/Bd4JYPtOSUuBu4BNwCm2N5ftTgYuAV5G6wTuiCdxIyJico16yebW1tvb61y9ExExPpKW2e4dWs9f5EZEVCShHxFRkYR+RERFxnIiNyK2kFlnfW1rDyFeoFaf95Ytst9tOvTzHyqGs6X+Q0W80GV6JyKiIgn9iIiKJPQjIiqS0I+IqEhCPyKiIgn9iIiKJPQjIiqS0I+IqEhCPyKiIgn9iIiKJPQjIiqS0I+IqEhCPyKiImO5MfrFkh6SdEej9nlJy8tj9eC9cyXNkvRUY92nGtvsL2mFpFWSFpebo0dERBeN5aOVLwEuAC4bLNh+9+CypPOBxxvt77M9r81+LgQWAt8DrgMOIzdGj4joqlGP9G3fDDzSbl05Wn8XcOVI+5C0OzDN9i1u3Yn9MuCocY82IiImZKJz+gcB623f26jNlvRDSTdJOqjUpgP9jTb9pdaWpIWS+iT1DQwMTHCIERExaKKhfzTPPcpfB+xpez/gL4ArJE0D2s3fe7id2l5iu9d2b09PzwSHGBERgzq+XaKkqcA7gP0Ha7Y3AhvL8jJJ9wF70zqyn9HYfAawttO+IyKiMxM50v9j4B7bz07bSOqRNKUsvxaYA/zE9jpgg6QDynmAY4FrJtB3RER0YCyXbF4J3AK8TlK/pBPKqgU8/wTuG4HbJf0I+CJwku3Bk8AnA/8ErALuI1fuRER03ajTO7aPHqZ+fJva1cDVw7TvA/Yd5/giImIS5S9yIyIqktCPiKhIQj8ioiIJ/YiIiiT0IyIqktCPiKhIQj8ioiIJ/YiIiiT0IyIqktCPiKhIQj8ioiIJ/YiIiiT0IyIqktCPiKhIQj8ioiIJ/YiIiiT0IyIqktCPiKjIWO6Re7GkhyTd0aidK+lBScvL44jGurMlrZK0UtKhjfr+klaUdYvLDdIjIqKLxnKkfwlwWJv6x2zPK4/rACTNpXXD9H3KNp+UNKW0vxBYCMwpj3b7jIiILWjU0Ld9M/DIGPd3JHCV7Y227wdWAfMl7Q5Ms32LbQOXAUd1OOaIiOjQROb0T5V0e5n+2bnUpgNrGm36S216WR5ab0vSQkl9kvoGBgYmMMSIiGjqNPQvBPYC5gHrgPNLvd08vUeot2V7ie1e2709PT0dDjEiIobqKPRtr7e92fYzwGeA+WVVPzCz0XQGsLbUZ7SpR0REF3UU+mWOftDbgcEre64FFkjaXtJsWidsb7W9Dtgg6YBy1c6xwDUTGHdERHRg6mgNJF0JHAzsKqkfOAc4WNI8WlM0q4ETAWzfKWkpcBewCTjF9uayq5NpXQn0MuD68oiIiC4aNfRtH92mfNEI7RcBi9rU+4B9xzW6iIiYVPmL3IiIiiT0IyIqktCPiKhIQj8ioiIJ/YiIiiT0IyIqktCPiKhIQj8ioiIJ/YiIiiT0IyIqktCPiKhIQj8ioiIJ/YiIiiT0IyIqktCPiKhIQj8ioiIJ/YiIiiT0IyIqMmroS7pY0kOS7mjU/l7SPZJul/RlSTuV+ixJT0laXh6famyzv6QVklZJWlxukB4REV00liP9S4DDhtRuAPa1/Xrgx8DZjXX32Z5XHic16hcCC4E55TF0nxERsYWNGvq2bwYeGVL7hu1N5en3gBkj7UPS7sA027fYNnAZcFRHI46IiI5Nxpz+nwPXN57PlvRDSTdJOqjUpgP9jTb9pdaWpIWS+iT1DQwMTMIQIyICJhj6kj4EbAIuL6V1wJ629wP+ArhC0jSg3fy9h9uv7SW2e2339vT0TGSIERHRMLXTDSUdB/wpcEiZssH2RmBjWV4m6T5gb1pH9s0poBnA2k77joiIznR0pC/pMOBM4G22n2zUeyRNKcuvpXXC9ie21wEbJB1Qrto5FrhmwqOPiIhxGfVIX9KVwMHArpL6gXNoXa2zPXBDufLye+VKnTcC/0vSJmAzcJLtwZPAJ9O6EuhltM4BNM8DREREF4wa+raPblO+aJi2VwNXD7OuD9h3XKOLiIhJlb/IjYioSEI/IqIiCf2IiIok9CMiKpLQj4ioSEI/IqIiCf2IiIok9CMiKpLQj4ioSEI/IqIiCf2IiIok9CMiKpLQj4ioSEI/IqIiCf2IiIok9CMiKpLQj4ioSEI/IqIio4a+pIslPSTpjkZtF0k3SLq3fN25se5sSaskrZR0aKO+v6QVZd3icoP0iIjoorEc6V8CHDakdhZwo+05wI3lOZLmAguAfco2n5Q0pWxzIbAQmFMeQ/cZERFb2Kihb/tm4JEh5SOBS8vypcBRjfpVtjfavh9YBcyXtDswzfYttg1c1tgmIiK6pNM5/d1srwMoX19d6tOBNY12/aU2vSwPrbclaaGkPkl9AwMDHQ4xIiKGmuwTue3m6T1CvS3bS2z32u7t6emZtMFFRNSu09BfX6ZsKF8fKvV+YGaj3QxgbanPaFOPiIgu6jT0rwWOK8vHAdc06gskbS9pNq0TtreWKaANkg4oV+0c29gmIiK6ZOpoDSRdCRwM7CqpHzgHOA9YKukE4KfAOwFs3ylpKXAXsAk4xfbmsquTaV0J9DLg+vKIiIguGjX0bR89zKpDhmm/CFjUpt4H7Duu0UVExKTKX+RGRFQkoR8RUZGEfkRERRL6EREVSehHRFQkoR8RUZGEfkRERRL6EREVSehHRFQkoR8RUZGEfkRERRL6EREVSehHRFQkoR8RUZGEfkRERRL6EREVSehHRFQkoR8RUZGOQ1/S6yQtbzyekPQBSedKerBRP6KxzdmSVklaKenQyXkJERExVqPeI3c4tlcC8wAkTQEeBL4MvBf4mO2PNNtLmgssAPYB9gC+KWnvxo3TIyJiC5us6Z1DgPtsPzBCmyOBq2xvtH0/sAqYP0n9R0TEGExW6C8Armw8P1XS7ZIulrRzqU0H1jTa9Jfa80haKKlPUt/AwMAkDTEiIiYc+pK2A94GfKGULgT2ojX1sw44f7Bpm83dbp+2l9jutd3b09Mz0SFGREQxGUf6hwO32V4PYHu97c22nwE+w6+ncPqBmY3tZgBrJ6H/iIgYo8kI/aNpTO1I2r2x7u3AHWX5WmCBpO0lzQbmALdOQv8RETFGHV+9AyDp5cCfACc2yh+WNI/W1M3qwXW275S0FLgL2ASckit3IiK6a0Khb/tJ4FVDaseM0H4RsGgifUZEROfyF7kRERVJ6EdEVCShHxFRkYR+RERFEvoRERVJ6EdEVCShHxFRkYR+RERFEvoRERVJ6EdEVCShHxFRkYR+RERFEvoRERVJ6EdEVCShHxFRkYR+RERFEvoRERVJ6EdEVGRCoS9ptaQVkpZL6iu1XSTdIOne8nXnRvuzJa2StFLSoRMdfEREjM9kHOm/yfY8273l+VnAjbbnADeW50iaCywA9gEOAz4pacok9B8REWO0JaZ3jgQuLcuXAkc16lfZ3mj7fmAVMH8L9B8REcOYaOgb+IakZZIWltputtcBlK+vLvXpwJrGtv2l9jySFkrqk9Q3MDAwwSFGRMSgqRPc/kDbayW9GrhB0j0jtFWbmts1tL0EWALQ29vbtk1ERIzfhI70ba8tXx8Cvkxruma9pN0ByteHSvN+YGZj8xnA2on0HxER49Nx6Et6haQdB5eBNwN3ANcCx5VmxwHXlOVrgQWStpc0G5gD3Npp/xERMX4Tmd7ZDfiypMH9XGH765J+ACyVdALwU+CdALbvlLQUuAvYBJxie/OERh8REePScejb/gnwO23qPwMOGWabRcCiTvuMiIiJyV/kRkRUJKEfEVGRhH5EREUS+hERFUnoR0RUJKEfEVGRhH5EREUS+hERFUnoR0RUJKEfEVGRhH5EREUS+hERFUnoR0RUJKEfEVGRhH5EREUS+hERFUnoR0RUJKEfEVGRidwYfaakb0m6W9Kdkk4r9XMlPShpeXkc0djmbEmrJK2UdOhkvICIiBi7idwYfRNwuu3bJO0ILJN0Q1n3MdsfaTaWNBdYAOwD7AF8U9LeuTl6RET3dHykb3ud7dvK8gbgbmD6CJscCVxle6Pt+4FVwPxO+4+IiPGblDl9SbOA/YDvl9Kpkm6XdLGknUttOrCmsVk/w/yQkLRQUp+kvoGBgckYYkREMAmhL2kH4GrgA7afAC4E9gLmAeuA8webttnc7fZpe4ntXtu9PT09Ex1iREQUEwp9SS+hFfiX2/4SgO31tjfbfgb4DL+ewukHZjY2nwGsnUj/ERExPhO5ekfARcDdtj/aqO/eaPZ24I6yfC2wQNL2kmYDc4BbO+0/IiLGbyJX7xwIHAOskLS81D4IHC1pHq2pm9XAiQC275S0FLiL1pU/p+TKnYiI7uo49G1/h/bz9NeNsM0iYFGnfUZExMTkL3IjIiqS0I+IqEhCPyKiIgn9iIiKJPQjIiqS0I+IqEhCPyKiIgn9iIiKJPQjIiqS0I+IqEhCPyKiIgn9iIiKJPQjIiqS0I+IqEhCPyKiIgn9iIiKJPQjIirS9dCXdJiklZJWSTqr2/1HRNSsq6EvaQrwCeBwYC6t++nO7eYYIiJq1u0j/fnAKts/sf1L4CrgyC6PISKiWt0O/enAmsbz/lKLiIgumNrl/tSm5uc1khYCC8vTn0tauUVHVY9dgYe39iBeCPR/tvYIYhh5jxaT8B59Tbtit0O/H5jZeD4DWDu0ke0lwJJuDaoWkvps927tcUQMJ+/RLa/b0zs/AOZImi1pO2ABcG2XxxARUa2uHunb3iTpVOBfgSnAxbbv7OYYIiJq1u3pHWxfB1zX7X4DyJRZvPDlPbqFyX7eedSIiNhG5WMYIiIqktB/kZL080nc13WSdpqs/cW2TZIlnd94foakc0fZ5qjh/vpe0kmSjp2ksb0tH+8yskzvvEhJ+rntHYbUptjevLXGFHWQ9DSwDvg92w9LOgPYwfa5I2xzCfAvtr84jn6m2t400fHGc+VI/0VO0sGSviXpCmCFpJdK+qykFZJ+KOlNpd3xkr4k6euS7pX04cY+VkvatSwfK+l2ST+S9Lmt9LLihW0TrROu/2PoCkmvkXRjeQ/dKGlPSX8AvA34e0nLJe01ZJtzyw8OJH1b0t9Jugk4TdIh5X28QtLFkrYv7VZL+htJt5V1v13qx0u6oCzvJunL5b38ozKO6nX96p3YIuYD+9q+X9LpALb/Y/mP8A1Je5d284D9gI3ASkn/aPvZj8WQtA/wIeDAcgS3S1dfRbyYfAK4vXnwUFwAXGb7Ukl/Diy2fZSkaxn7kf5Otv9Q0kuBe4FDbP9Y0mXAycDHS7uHbf+upP8OnAG8b8h+FgM32X57+bDHHYgc6W8jbrV9f1n+T8DnAGzfAzwADIb+jbYft/00cBfP/zPtPwK+aPvhsv0jW3zk8aJk+wngMuD9Q1b9PnBFWf4crffjeH2+fH0dcL/tH5fnlwJvbLT7Uvm6DJjVZj9/BFxYxrvZ9uMdjGWbk9DfNvyisdzu840GbWwsb+b5v+mJNp+FFDGMjwMnAK8YoU0n76fB9/NI72X49fu53Xs5hpHQ3/bcDLwHoEzr7AmM9QPrbgTeJelVZftM78Swym+CS2kF/6Dv0vp4FWi9D79TljcAO46zi3uAWZJ+qzw/BrhpHNvfSGs6CElTJE0bZ//bpIT+tueTwBRJK2j9mny87Y2jbANA+UiMRcBNkn4EfHTLDTO2EefT+mTMQe8H3ivpdlohfVqpXwX8ZTkpuxdjUKYh3wt8obyfnwE+NY6xnQa8qWy7DNhnHNtus3LJZkRERXKkHxFRkYR+RERFEvoRERVJ6EdEVCShHxFRkYR+RERFEvoRERVJ6EdEVOT/Ax9boR/6rGm0AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ironic tweets -  1911\n",
      "Non Ironic tweets -  1923\n",
      "Percentage of ironic tweets -  49.84350547730829\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "train_data_ntrue=train_data['label'].sum()\n",
    "train_data_nfalse=train_data['label'].count()-train_data_ntrue\n",
    "values=[train_data_ntrue,train_data_nfalse]\n",
    "names=['Ironic','Not ironic']\n",
    "plt.bar(names,values)\n",
    "plt.suptitle('Train data set - distribution')\n",
    "plt.show()\n",
    "print('Ironic tweets - ',train_data_ntrue)\n",
    "print('Non Ironic tweets - ',train_data_nfalse)\n",
    "print('Percentage of ironic tweets - ',train_data_ntrue*1.0/train_data['label'].count()*100.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ironic tweets -  311\n",
      "Non Ironic tweets -  473\n",
      "Percentage of ironic tweets -  39.66836734693878\n"
     ]
    }
   ],
   "source": [
    "test_data_ntrue=test_data['label'].sum()\n",
    "test_data_nfalse=test_data['label'].count()-test_data_ntrue\n",
    "values=[test_data_ntrue,test_data_nfalse]\n",
    "names=['Ironic','Non Ironic']\n",
    "plt.suptitle('Test data set - distribution')\n",
    "plt.bar(names,values)\n",
    "plt.show()\n",
    "print('Ironic tweets - ',test_data_ntrue)\n",
    "print('Non Ironic tweets - ',test_data_nfalse)\n",
    "print('Percentage of ironic tweets - ',test_data_ntrue*1.0/test_data['label'].count()*100.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conclusion:\n",
    "\n",
    "While the training data is **balanced** in the number of ironic and non ironic tweets, the same can't be said for the test data set originnaly provided by the organization.\n",
    "\n",
    "In our second graph, its visually palpable that the number of non ironic tweets is significantly larger."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bag of words\n",
    "\n",
    "Now that we have the data in a pandas data set we need to proceed our path of finding an accurate model to identify ironic tweets. For that we need to parse our tweets to a **bag of words** model format.\n",
    "\n",
    "A bag of words is a model which tweet will see their words tokenized and counted by a specified formula. Where we have 2 essential paths that we can follow:\n",
    "\n",
    "* Use a simple counting of words.\n",
    "* Use the TF-IDF measure\n",
    "\n",
    "##### The process of getting as input the raw text and output a bag of words is called **Vectorization**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial analysis\n",
    "\n",
    "\n",
    "There are two important questions that we need to be able to answer in order to proceed in our model design and also a raw analysis without pre processing, this way we can estimate the level of pre processing we need in order to achieve a reasonable answer and also keep track of degree of improvement we have in each attempt we try.\n",
    "\n",
    "* Does TF-IDF measure perform better that a simple counting of words?\n",
    "* How good performs the simplest model in our dataset without preprocessing?\n",
    "\n",
    "In order to have a objective evaluation criteria to our final answer to this problem, it is important to make a fast initial analysis to the data without any kind of pre processing to the data, using the simplest model possible, a **Gaussian naïve Bayes**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple Word Counter Vetorization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "count_vectorizer = CountVectorizer(analyzer='word', stop_words='english', lowercase=False)\n",
    "\n",
    "X_train=count_vectorizer.fit_transform(train_data['tweet']).toarray()\n",
    "y_train=train_data['label']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we just Transform. Because the vocabulary is the one from the test set\n",
    "X_test=count_vectorizer.transform(test_data['tweet']).toarray()\n",
    "y_test=test_data['label']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "classificator=GaussianNB()\n",
    "\n",
    "classificator.fit(X_train,y_train)\n",
    "#Predicition\n",
    "y_predicted=classificator.predict(X_test)\n",
    "\n",
    "\n",
    "\n",
    "#Metrics Raw\n",
    "accuracy_value=accuracy_score(y_test,y_predicted)\n",
    "precision_value=precision_score(y_test,y_predicted,average='weighted')\n",
    "f1_value=f1_score(y_test,y_predicted,average='weighted')\n",
    "\n",
    "\n",
    "initial_word_count_conclusion=pandas.DataFrame(\n",
    "    {\n",
    "    'Our Results':[accuracy_value,precision_value,f1_value],\n",
    "    'Winners Result':[0.7347,0.6304,0.8006]\n",
    "    } , index=['Accuracy','Precision','F1-Value'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF Vetorization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tf_idf_vectorizer = TfidfVectorizer(analyzer='word', stop_words='english', lowercase=False)\n",
    "\n",
    "X_train=tf_idf_vectorizer.fit_transform(train_data['tweet']).toarray()\n",
    "y_train=train_data['label']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test=tf_idf_vectorizer.transform(test_data['tweet']).toarray()\n",
    "y_test=test_data['label']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "classificator=GaussianNB()\n",
    "\n",
    "classificator.fit(X_train,y_train)\n",
    "#Predicition\n",
    "y_predicted=classificator.predict(X_test)\n",
    "\n",
    "\n",
    "\n",
    "#Metrics Raw\n",
    "accuracy_value=accuracy_score(y_test,y_predicted)\n",
    "precision_value=precision_score(y_test,y_predicted,average='weighted')\n",
    "f1_value=f1_score(y_test,y_predicted,average='weighted')\n",
    "\n",
    "\n",
    "initial_tf_idf_conclusion=pandas.DataFrame(\n",
    "    {\n",
    "    'Our Results':[accuracy_value,precision_value,f1_value],\n",
    "    'Winners Result':[0.7347,0.6304,0.8006]\n",
    "    } , index=['Accuracy','Precision','F1-Value'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initial Analysis conclusion:\n",
    "\n",
    "**The differences between the competition results and our naive model are relevant. Preprocessing of data is required to improve this values. Other models techniques should also be used.** \n",
    "\n",
    "\n",
    "Other element relevant is that using simple word counting or TF-IDF doesn't produce any kind of relevant difference in the results achieved. For that reason **TF-IDF will hold**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Simple Word Counting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Our Results</th>\n",
       "      <th>Winners Result</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Accuracy</th>\n",
       "      <td>0.510204</td>\n",
       "      <td>0.7347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Precision</th>\n",
       "      <td>0.556403</td>\n",
       "      <td>0.6304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1-Value</th>\n",
       "      <td>0.509943</td>\n",
       "      <td>0.8006</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Our Results  Winners Result\n",
       "Accuracy      0.510204          0.7347\n",
       "Precision     0.556403          0.6304\n",
       "F1-Value      0.509943          0.8006"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "initial_word_count_conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Our Results</th>\n",
       "      <th>Winners Result</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Accuracy</th>\n",
       "      <td>0.514031</td>\n",
       "      <td>0.7347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Precision</th>\n",
       "      <td>0.550978</td>\n",
       "      <td>0.6304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1-Value</th>\n",
       "      <td>0.516916</td>\n",
       "      <td>0.8006</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Our Results  Winners Result\n",
       "Accuracy      0.514031          0.7347\n",
       "Precision     0.550978          0.6304\n",
       "F1-Value      0.516916          0.8006"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "initial_tf_idf_conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO -> Remove non english words? / Tokenize emojis / Lemmatization "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data pre processing process\n",
    "\n",
    "The downfall of the initial results can be easily explained by multiple reasons:\n",
    "\n",
    "* We are dealing social network data. That data contains lots of useless information like links, mentions or emojis and also lots of slangs and non standard vocabulary\n",
    "\n",
    "* Didn't apply any type of Stemming or Lemmatization\n",
    "\n",
    "* Used a simple Gaussian naïve Bayes rather than a complex neural network.\n",
    "\n",
    "* Used the embedded tokenizer of sci kit learn rather than dedicated ones.\n",
    "\n",
    "* The initial vocabulary is very large. 14k words. This decreases perfomance and increases overfitting to the train data.\n",
    "\n",
    "* A final problem that could be related with the poor perfomance of the initial model is the traditional downfalls of NLP algorithms in finding contraditions. Irony many times has contradictions implied.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove Web Hyperlinks from tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_data['tweet']=train_data['tweet'].str.replace('http\\S+|www.\\S+', '', case=False)\n",
    "\n",
    "#Deletes any kind of empty tweet that was left after removing links\n",
    "train_data.replace('', numpy.nan, inplace=True)\n",
    "train_data.dropna(subset=['tweet'],inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Normalization of Twitter mentions\n",
    "\n",
    "In twitter is mandatory to mention the person that we reply with their personal nickname. In this Social Network this mentions are done using \"@\" followed by a single word that identifies the nickname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['tweet']=train_data['tweet'].str.replace('@\\S+', '<person>', case=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove Numbers from the tweets\n",
    "\n",
    "Numbers don't introduce power to a language of ironic tweets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['tweet']=train_data['tweet'].str.replace('d+', '', case=False)\n",
    "\n",
    "#Deletes any kind of empty tweet that was left after removing numbers\n",
    "train_data.replace('', numpy.nan, inplace=True)\n",
    "train_data.dropna(subset=['tweet'],inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Contradictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys  \n",
    "import contractions\n",
    "\n",
    "contradictions_fixed=[]\n",
    "\n",
    "for i in range(len(train_data)):\n",
    "    contradictions_fixed.append(contractions.fix(train_data['tweet'][i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "  \n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "lemmatization_result = []\n",
    "\n",
    "for i in range(len(contradictions_fixed)):\n",
    "    tweet = lemmatizer.lemmatize(contradictions_fixed[i])\n",
    "    lemmatization_result.append(tweet)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenization and Stemming with normalization of uppercase words.\n",
    "\n",
    "Goal is to reduce the vocabulary to the absolutely necessary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "ps = PorterStemmer()\n",
    "corpus = []\n",
    "\n",
    "for i in range(len(lemmatization_result)):\n",
    "    # get review and remove non alpha chars\n",
    "    tweet = re.sub('[^a-zA-Z]', ' ', lemmatization_result[i])\n",
    "    # to lower-case and tokenize\n",
    "    tweet = tweet.lower().split()\n",
    "    # stemming and stop word removal\n",
    "    tweet = ' '.join([ps.stem(w) for w in tweet if not w in set(stopwords.words('english'))])\n",
    "    corpus.append(tweet)\n",
    "\n",
    "vectorizer = TfidfVectorizer(max_features = 500)\n",
    "\n",
    "X_train=vectorizer.fit_transform(corpus).toarray()\n",
    "y_train=train_data['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500\n"
     ]
    }
   ],
   "source": [
    "print(len(vectorizer.vocabulary_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14042"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "14042"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Fazer aquela cena dos vetores de similitude vai curtir -> Encontrar duplicados\n",
    "* Remover Numeros\n",
    "* Fazer Stemming\n",
    "* Fazer Lemmazation\n",
    "* Fazer contradictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.72      0.70       473\n",
      "           1       0.53      0.48      0.50       311\n",
      "\n",
      "    accuracy                           0.62       784\n",
      "   macro avg       0.60      0.60      0.60       784\n",
      "weighted avg       0.62      0.62      0.62       784\n",
      "\n",
      "Confusion Matrix\n",
      "[[340 133]\n",
      " [162 149]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "X_test=vectorizer.transform(test_data['tweet']).toarray()\n",
    "y_test=test_data['label']\n",
    "\n",
    "classificator.fit(X_train,y_train)\n",
    "#Predicition\n",
    "y_predicted=classificator.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test,y_predicted))\n",
    "print(\"Confusion Matrix\")\n",
    "print(confusion_matrix(y_test, y_predicted))\n",
    "\n",
    "accuracy_value=accuracy_score(y_test,y_predicted)\n",
    "precision_value=precision_score(y_test,y_predicted,average='weighted')\n",
    "f1_value=f1_score(y_test,y_predicted,average='weighted')\n",
    "\n",
    "actual_conclusion=pandas.DataFrame(\n",
    "    {\n",
    "    'Our Results':[accuracy_value,precision_value,f1_value],\n",
    "    'Winners Result':[0.7347,0.6304,0.8006]\n",
    "    } , index=['Accuracy','Precision','F1-Value'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Our Results</th>\n",
       "      <th>Winners Result</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Accuracy</th>\n",
       "      <td>0.623724</td>\n",
       "      <td>0.7347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Precision</th>\n",
       "      <td>0.618216</td>\n",
       "      <td>0.6304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1-Value</th>\n",
       "      <td>0.620120</td>\n",
       "      <td>0.8006</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Our Results  Winners Result\n",
       "Accuracy      0.623724          0.7347\n",
       "Precision     0.618216          0.6304\n",
       "F1-Value      0.620120          0.8006"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actual_conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF Word Counter Vetorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.79      0.73       473\n",
      "           1       0.58      0.45      0.50       311\n",
      "\n",
      "    accuracy                           0.65       784\n",
      "   macro avg       0.63      0.62      0.62       784\n",
      "weighted avg       0.64      0.65      0.64       784\n",
      "\n",
      "[[372 101]\n",
      " [172 139]]\n"
     ]
    }
   ],
   "source": [
    "classifier=GaussianNB()\n",
    "\n",
    "classifier.fit(X_train,y_train)\n",
    "\n",
    "y_predicted=classifier.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test,y_predicted))\n",
    "print(confusion_matrix(y_test, y_predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.66      0.66       473\n",
      "           1       0.47      0.47      0.47       311\n",
      "\n",
      "    accuracy                           0.58       784\n",
      "   macro avg       0.56      0.56      0.56       784\n",
      "weighted avg       0.58      0.58      0.58       784\n",
      "\n",
      "[[311 162]\n",
      " [165 146]]\n"
     ]
    }
   ],
   "source": [
    "# Decision Tree\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "classifier = DecisionTreeClassifier()\n",
    "classifier.fit(X_train, y_train)\n",
    "y_predicted = classifier.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test,y_predicted))\n",
    "print(confusion_matrix(y_test, y_predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.68      0.68       473\n",
      "           1       0.52      0.52      0.52       311\n",
      "\n",
      "    accuracy                           0.62       784\n",
      "   macro avg       0.60      0.60      0.60       784\n",
      "weighted avg       0.62      0.62      0.62       784\n",
      "\n",
      "[[321 152]\n",
      " [148 163]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ruben/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Neural Network\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "classifier = MLPClassifier()\n",
    "classifier.fit(X_train, y_train)\n",
    "y_predicted = classifier.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test,y_predicted))\n",
    "print(confusion_matrix(y_test, y_predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KNN\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "classifier = KNeighborsClassifier()\n",
    "classifier.fit(X_train, y_train)\n",
    "y_predicted = classifier.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test,y_predicted))\n",
    "print(confusion_matrix(y_test, y_predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVM\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "classifier = SVC()\n",
    "classifier.fit(X_train, y_train)\n",
    "y_predicted=classifier.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test,y_predicted))\n",
    "print(confusion_matrix(y_test, y_predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
