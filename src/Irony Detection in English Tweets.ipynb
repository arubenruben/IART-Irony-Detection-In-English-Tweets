{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Irony Detection in English \n",
    "\n",
    "#### The goal of this project consists in training a model capable of performing the task of classification if a tweet in English is ironic or don’t.\n",
    "\n",
    "Using different classification techniques we intend to find the one that performs better using as training data a data set with around 4000 tweets of different types.\n",
    "\n",
    "This project was made by 3rd students as part of the Artificial Intelligence at FEUP. You are free to use the code for any purpose, but beware that this is just an academia project in an introductory course to Artificial Intelligence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Datasets:\n",
    "\n",
    "The data sets for this project are not own by our group, they are supplied by SemEval competition and are free to use for academic purpose only outside of the competition.\n",
    "\n",
    "There are two data sets available, one marked for train other for testing. Originally they were in .txt format, but in order to simplify the work of the pandas library, we manually converted those files to .csv\n",
    "\n",
    "**SemEval organization themselves provide already a division of the dataset in two subsets, a test data and a train data.**\n",
    "\n",
    "This division is usefull for the final evaluation of our work. Since the competition was in 2018, the ranking of the participants for that dataset is already public. This way we are able to keep track of which place we could score in that professional competition\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](../assets/ranking.png)\n",
    "##### Fig1: Ranking of the SemEval competition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Problem with word delimeter\n",
    "\n",
    "Pandas is a library perfect for the job of reading the data from a file, since it setup automaticaly the capability of seeing that data in a formatted organized way.\n",
    "\n",
    "Pandas has specific functions to read from different formats. 4000 tweets in JSON would turn the data file really dense in information.\n",
    "Since we are dealing with just 2 attributes is pointless to make our life harder in this step. We choosed .csv format to represent the data\n",
    "\n",
    "CSV files dealing with text rise other problem, the fact that people use comma in their texts, pandas. So we introduce other delimiter that exists in Portuguese, but doesn't exist in english \"_ç\", so we are able to do the task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "import numpy\n",
    "\n",
    "train_data=pandas.read_csv('data/train.csv', engine='python', encoding=\"utf-8\",delimiter=\"_ç\")\n",
    "test_data=pandas.read_csv('data/test-labeled.csv',engine='python', encoding=\"utf-8\",delimiter=\"_ç\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Sweet United Nations video. Just in time for C...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>@mrdahl87 We are rumored to have talked to Erv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Hey there! Nice to see you Minnesota/ND Winter...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>3 episodes left I'm dying over here</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>\"I can't breathe!\" was chosen as the most nota...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                              tweet\n",
       "0      1  Sweet United Nations video. Just in time for C...\n",
       "1      1  @mrdahl87 We are rumored to have talked to Erv...\n",
       "2      1  Hey there! Nice to see you Minnesota/ND Winter...\n",
       "3      0                3 episodes left I'm dying over here\n",
       "4      1  \"I can't breathe!\" was chosen as the most nota..."
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>@Callisto1947 Can U Help?||More conservatives ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Just walked in to #Starbucks and asked for a \"...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>#NOT GONNA WIN http://t.co/Mc9ebqjAqj</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>@mickymantell He is exactly that sort of perso...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>So much #sarcasm at work mate 10/10 #boring 10...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                              tweet\n",
       "0      0  @Callisto1947 Can U Help?||More conservatives ...\n",
       "1      1  Just walked in to #Starbucks and asked for a \"...\n",
       "2      0              #NOT GONNA WIN http://t.co/Mc9ebqjAqj\n",
       "3      0  @mickymantell He is exactly that sort of perso...\n",
       "4      1  So much #sarcasm at work mate 10/10 #boring 10..."
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bag of words\n",
    "\n",
    "Now that we have the data in a pandas data set we need to proceed our path of finding an accurate model to identify ironic tweets. For that we need to parse our tweets to a **bag of words** model format.\n",
    "\n",
    "A bag of words is a model which tweet will see their words tokenized and counted by a specified formula. Where we have essential 2 paths that we can follow:\n",
    "\n",
    "* Use a simple counting of words.\n",
    "* Use the TF-IDF measure\n",
    "\n",
    "##### The process of getting as input the raw text and output a bag of words is called **Vectorization**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial analysis\n",
    "\n",
    "In order to have a objective evaluation criteria to our final answer to this problem, it is important to make a fast initial analysis to the data without any kind of pre processing to the data, using the simplest model possible a naive bayes analyses.\n",
    "\n",
    "#### Simple Word Counter Vetorization\n",
    "#### Train Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "count_vectorizer = CountVectorizer(analyzer='word', stop_words='english', lowercase=False)\n",
    "\n",
    "X_train=count_vectorizer.fit_transform(train_data['tweet']).toarray()\n",
    "y_train=train_data['label']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we just Transform. Because the vocabulary is the on from the test set\n",
    "X_test=count_vectorizer.transform(test_data['tweet']).toarray()\n",
    "y_test=test_data['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.42      0.51       473\n",
      "           1       0.42      0.65      0.51       311\n",
      "\n",
      "    accuracy                           0.51       784\n",
      "   macro avg       0.53      0.53      0.51       784\n",
      "weighted avg       0.56      0.51      0.51       784\n",
      "\n",
      "[[199 274]\n",
      " [110 201]]\n"
     ]
    }
   ],
   "source": [
    "classificator=GaussianNB()\n",
    "\n",
    "classificator.fit(X_train,y_train)\n",
    "\n",
    "y_predicted=classificator.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test,y_predicted))\n",
    "print(confusion_matrix(y_test, y_predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF Word Counter Vetorization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tf_idf_vectorizer=TfidfVectorizer(analyzer='word', stop_words='english', lowercase=False)\n",
    "\n",
    "X_train=tf_idf_vectorizer.fit_transform(train_data['tweet']).toarray()\n",
    "y_train=train_data['label']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test=tf_idf_vectorizer.transform(test_data['tweet']).toarray()\n",
    "y_test=test_data['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.45      0.53       473\n",
      "           1       0.42      0.60      0.50       311\n",
      "\n",
      "    accuracy                           0.51       784\n",
      "   macro avg       0.53      0.53      0.51       784\n",
      "weighted avg       0.55      0.51      0.52       784\n",
      "\n",
      "Confusion Matrix\n",
      "[[215 258]\n",
      " [123 188]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "classificator=GaussianNB()\n",
    "\n",
    "classificator.fit(X_train,y_train)\n",
    "#Predicition\n",
    "y_predicted=classificator.predict(X_test)\n",
    "\n",
    "\n",
    "\n",
    "#Metrics Raw\n",
    "accuracy_value=accuracy_score(y_test,y_predicted)\n",
    "precision_value=precision_score(y_test,y_predicted,average='weighted')\n",
    "f1_value=f1_score(y_test,y_predicted,average='weighted')\n",
    "\n",
    "print(classification_report(y_test,y_predicted))\n",
    "print(\"Confusion Matrix\")\n",
    "print(confusion_matrix(y_test, y_predicted))\n",
    "\n",
    "\n",
    "\n",
    "initial_conclusion=pandas.DataFrame(\n",
    "    {\n",
    "    'Our Results':[accuracy_value,precision_value,f1_value],\n",
    "    'Winners Result':[0.7347,0.6304,0.8006]\n",
    "    } , index=['Accuracy','Precision','F1-Value'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusions\n",
    "\n",
    "The raw analysis of the perfomance of the simple model is pretty bellow the best scores of the competition:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Our Results</th>\n",
       "      <th>Winners Result</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Accuracy</th>\n",
       "      <td>0.514031</td>\n",
       "      <td>0.7347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Precision</th>\n",
       "      <td>0.550978</td>\n",
       "      <td>0.6304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1-Value</th>\n",
       "      <td>0.516916</td>\n",
       "      <td>0.8006</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Our Results  Winners Result\n",
       "Accuracy      0.514031          0.7347\n",
       "Precision     0.550978          0.6304\n",
       "F1-Value      0.516916          0.8006"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "initial_conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The differences are relevant. We need to introduce data pre processing to our project in order to improve the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
