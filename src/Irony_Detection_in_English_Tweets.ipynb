{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Irony Detection in English\n",
    "\n",
    "#### The goal of this project consists in training models capable handling classificating irony in  English  tweet. It has two different tasks.\n",
    "\n",
    "* Task1: Create a Model for perform a binary classification if a tweet is ironic or not\n",
    "* Task2: Create a Model to determine the type of irony\n",
    "\n",
    "This project was originally introduced as a task for a Machine Learning competition, the [SemEval2018](https://competitions.codalab.org/competitions/17468#participate)\n",
    "\n",
    "Using different classification techniques we intend to find the best model that performs better in  each of the two purposed tasks.\n",
    "\n",
    "This project was made by 3 students as part of the Artificial Intelligence course at FEUP. You are free to use the code for any purpose, but beware that this is just an academia project in an introductory course to Artificial Intelligence.\n",
    "\n",
    "* André Malheiro up201706280@fe.up.pt\n",
    "* Diogo Gomes up201806572@fe.up.pt\n",
    "* Rúben Almeida up201704618@fe.up.pt\n",
    "\n",
    "Libraries Used: \n",
    "* Pandas\n",
    "* Numpy\n",
    "* Scikit-learn\n",
    "* Matplotlib\n",
    "* nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Datasets:\n",
    "\n",
    "The data sets for this project are not owned by our group, they are supplied by SemEval competition and are free to use for academic purposes only outside of the competition.\n",
    "\n",
    "Both the tasks use the same two datasets, but marked in the proprer way according to the task. The first one is marked in binary way, where 1 stands for ironic tweet and 0 for non ironic tweet\n",
    "\n",
    "About the datasets, one is marked for train and the other for testing. Originally they were in .txt format, but in order to simplify the work of the pandas library, we manually converted those files to .csv\n",
    "\n",
    "**SemEval organization themselves already provide a division of the dataset in two subsets, a test dataset and a train dataset.**\n",
    "\n",
    "This division is useful for the final evaluation of our work. Since the competition was in 2018, the ranking of the participants for that dataset is already public. This way we are able to keep track of which place we could score in that professional competition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](../assets/ranking.png)\n",
    "##### Fig1: Ranking for task 1 of the SemEval competition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](../assets/ranking2.png)\n",
    "##### Fig1: Ranking for task 2 of the SemEval competition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Problem with word delimeter\n",
    "\n",
    "Pandas is a library perfect for the job of reading data from a file, since it setup automaticaly the capability of seeing that data in a formatted organized way.\n",
    "\n",
    "Pandas has specific functions to read from different formats. The datasets are originally in .txt format, a conversion for either JSON or CSV, formats accepted by Pandas needed to be done. 4000 tweets in JSON would turn the data file really dense in information.\n",
    "Since we are dealing with just 2 attributes, it is pointless to make our life harder in this step. \n",
    "\n",
    "**We chosed .csv format to represent the data**\n",
    "\n",
    "CSV files dealing with text rise other problem, the fact that people use comma in their texts, pandas. So we introduce other delimiter,'\\t', so we are able to do the task"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1: Ironic vs. non-ironic\n",
    "\n",
    "### Create a classificator that could handle proprely this binary classification task.\n",
    "\n",
    "In this first task we will use the dataset split the way it was provided by the competition\n",
    "\n",
    "In the second task we will use other techniques and apply other techniques like **cross validation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, HTML\n",
    "import pandas\n",
    "import numpy\n",
    "\n",
    "train_data=pandas.read_csv('data/task1/train.csv',  delimiter = '\\t', quoting = 3, encoding=\"utf-8\")\n",
    "test_data=pandas.read_csv('data/task1/test-labeled.csv', delimiter = '\\t', quoting = 3, encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analising the datasets\n",
    "\n",
    "Some initial considerations should be done in order to ensure the quality of the data. The data provided doesn't contain blank fields. \n",
    "\n",
    "Testing proprelly the existance of duplicates in the datasets would require knowledge outside the scope of the course, so we assume that there aren't duplicate data in the dataset.\n",
    "\n",
    "\n",
    "**One very important consideration regarding the data is the possibility of the dataset being unbalanced**. With both of our data sets loaded, we can use **Matplotlib** to determine if that consideration holds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "train_data_ntrue=train_data['label'].sum()\n",
    "train_data_nfalse=train_data['label'].count()-train_data_ntrue\n",
    "values=[train_data_ntrue,train_data_nfalse]\n",
    "names=['Ironic','Not ironic']\n",
    "plt.bar(names,values)\n",
    "plt.suptitle('Train data set - distribution')\n",
    "plt.show()\n",
    "print('Ironic tweets - ',train_data_ntrue)\n",
    "print('Non Ironic tweets - ',train_data_nfalse)\n",
    "print('Percentage of ironic tweets - ',train_data_ntrue*1.0/train_data['label'].count()*100.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_ntrue=test_data['label'].sum()\n",
    "test_data_nfalse=test_data['label'].count()-test_data_ntrue\n",
    "values=[test_data_ntrue,test_data_nfalse]\n",
    "names=['Ironic','Non Ironic']\n",
    "plt.suptitle('Test data set - distribution')\n",
    "plt.bar(names,values)\n",
    "plt.show()\n",
    "print('Ironic tweets - ',test_data_ntrue)\n",
    "print('Non Ironic tweets - ',test_data_nfalse)\n",
    "print('Percentage of ironic tweets - ',test_data_ntrue*1.0/test_data['label'].count()*100.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conclusion:\n",
    "\n",
    "While the training data is **balanced** in the number of ironic and non ironic tweets, the same can't be said for the test data set originnaly provided by the organization.\n",
    "\n",
    "In our second graph, its visually palpable that the number of non ironic tweets is significantly larger."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bag of words\n",
    "\n",
    "Now that we have the data in a pandas data set we need to proceed our path of finding an accurate model to identify ironic tweets. For that we need to parse our tweets to a **bag of words** model format.\n",
    "\n",
    "A bag of words is a model which tweet will see their words tokenized and counted by a specified formula. Where we have 2 essential paths that we can follow:\n",
    "\n",
    "* Use a simple counting of words.\n",
    "* Use the TF-IDF measure\n",
    "\n",
    "##### The process of getting as input the raw text and output a bag of words is called **Vectorization**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial analysis\n",
    "\n",
    "\n",
    "There are two important questions that we need to be able to answer in order to proceed in our model design and also a raw analysis without pre processing, this way we can estimate the level of pre processing we need in order to achieve a reasonable answer and also keep track of degree of improvement we have in each attempt we try.\n",
    "\n",
    "* Does TF-IDF measure perform better that a simple counting of words?\n",
    "* How good performs the simplest model in our dataset without preprocessing?\n",
    "\n",
    "In order to have a objective evaluation criteria to our final answer to this problem, it is important to make a fast initial analysis to the data without any kind of pre processing to the data, using the simplest model possible, a **Gaussian Naïve Bayes**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple Word Counter Vetorization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "count_vectorizer = CountVectorizer(analyzer='word', stop_words='english', lowercase=False)\n",
    "\n",
    "X_train=count_vectorizer.fit_transform(train_data['tweet']).toarray()\n",
    "y_train=train_data['label']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we just Transform. Because the vocabulary is the one from the test set\n",
    "X_test=count_vectorizer.transform(test_data['tweet']).toarray()\n",
    "y_test=test_data['label']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "classificator=GaussianNB()\n",
    "\n",
    "classificator.fit(X_train,y_train)\n",
    "#Predicition\n",
    "y_predicted=classificator.predict(X_test)\n",
    "\n",
    "\n",
    "\n",
    "#Metrics Raw\n",
    "accuracy_value=accuracy_score(y_test,y_predicted)\n",
    "precision_value=precision_score(y_test,y_predicted,average='weighted')\n",
    "f1_value=f1_score(y_test,y_predicted,average='weighted')\n",
    "\n",
    "\n",
    "initial_word_count_conclusion=pandas.DataFrame(\n",
    "    {\n",
    "    'Our Results':[accuracy_value,precision_value,f1_value],\n",
    "    'Winners Result':[0.7347,0.6304,0.8006]\n",
    "    } , index=['Accuracy','Precision','F1-Value'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF Vetorization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tf_idf_vectorizer = TfidfVectorizer(analyzer='word', stop_words='english', lowercase=False)\n",
    "\n",
    "X_train=tf_idf_vectorizer.fit_transform(train_data['tweet']).toarray()\n",
    "y_train=train_data['label']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test=tf_idf_vectorizer.transform(test_data['tweet']).toarray()\n",
    "y_test=test_data['label']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "classificator=GaussianNB()\n",
    "\n",
    "classificator.fit(X_train,y_train)\n",
    "#Predicition\n",
    "y_predicted=classificator.predict(X_test)\n",
    "\n",
    "\n",
    "\n",
    "#Metrics Raw\n",
    "accuracy_value=accuracy_score(y_test,y_predicted)\n",
    "precision_value=precision_score(y_test,y_predicted,average='weighted')\n",
    "f1_value=f1_score(y_test,y_predicted,average='weighted')\n",
    "\n",
    "\n",
    "initial_tf_idf_conclusion=pandas.DataFrame(\n",
    "    {\n",
    "    'Our Results':[accuracy_value,precision_value,f1_value],\n",
    "    'Winners Result':[0.7347,0.6304,0.8006]\n",
    "    } , index=['Accuracy','Precision','F1-Value'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initial Analysis conclusion:\n",
    "\n",
    "* The differences between the competition results and our naive model are relevant. Preprocessing of data is required to improve this values. Other models techniques should also be used.\n",
    "\n",
    "\n",
    "* Other element relevant is that using simple word counting or TF-IDF doesn't produce any kind of relevant difference in the results achieved. For that reason **TF-IDF will hold**\n",
    "\n",
    "\n",
    "* One naive classificator without pre processing is just a random classifier. It's correctness because of the randomness is around 50% as expected\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Simple Word Counting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "initial_word_count_conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_tf_idf_conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initial Vocabulary \n",
    "Without any pre processing the vectorization of the raw data has the following number of words:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(tf_idf_vectorizer.vocabulary_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**This would create an input matrix with 14042 collumns. That number is not reasonable for no algorithm. Preprocessing outh to reduce this value**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing Pipeline\n",
    "\n",
    "The downfall of the initial results can be easily explained by multiple reasons:\n",
    "\n",
    "* We are dealing social network data. That data contains lots of useless information like links, mentions or emojis and also lots of slangs and non standard vocabulary\n",
    "\n",
    "* Didn't apply any type of Stemming or Lemmatization\n",
    "\n",
    "* Used a simple Gaussian naïve Bayes rather than a complex neural network.\n",
    "\n",
    "* Used the embedded tokenizer of sci kit learn rather than dedicated ones.\n",
    "\n",
    "* The initial vocabulary is very large. 14k words. This decreases perfomance and increases overfitting to the train data.\n",
    "\n",
    "* A final problem that could be related with the poor perfomance of the initial model is the traditional downfalls of NLP algorithms in finding contraditions. Irony many times has contradictions implied.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove Web Hyperlinks from tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_data['tweet']=train_data['tweet'].str.replace('http\\S+|www.\\S+', '', case=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Normalization of Twitter mentions\n",
    "\n",
    "In twitter is mandatory to mention the person that we reply with their personal nickname. In this Social Network this mentions are done using \"@\" followed by a single word that identifies the nickname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['tweet']=train_data['tweet'].str.replace('@\\S+', '', case=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove Numbers from the tweets\n",
    "\n",
    "Numbers don't introduce power to a language of ironic tweets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['tweet']=train_data['tweet'].str.replace('\\d+', '', case=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove Hashtags\n",
    "\n",
    "Treat Hashtags as simple words by removing the \"#\" before them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['tweet']=train_data['tweet'].str.replace('#', '', case=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert emojis and emoticons to text\n",
    "\n",
    "For this job we use one of multiple open source library for the job, the choosed emoji because it was the best rated in the web"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import emoji\n",
    "import re\n",
    "\n",
    "emoji_result=[]\n",
    "\n",
    "for i in range(len(train_data)):\n",
    "    demojize_result=emoji.demojize(train_data['tweet'][i])\n",
    "    # Remove the \":\" from the convertion made by emoji\n",
    "    demojize_result=re.sub(\":\", \" \", demojize_result)\n",
    "    demojize_result=re.sub(\"_\", \" \", demojize_result)\n",
    "    demojize_result=re.sub(\"-\", \" \", demojize_result)\n",
    "    train_data['tweet'][i]=demojize_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Contradictions\n",
    "\n",
    "Contractions is a native library of python that deals with a sharp task in NLP in English Language. Words like \"Can't\" would generate two tokens. To avoids this, we should convert this cases for \"Can not\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import contractions\n",
    "\n",
    "for i in range(len(train_data)):\n",
    "    train_data['tweet'][i]=contractions.fix(train_data['tweet'][i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lemmatization\n",
    "According with Wiki Lemmatization is: \"In computational linguistics, lemmatisation is the algorithmic process of determining the lemma of a word based on its intended meaning.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "  \n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "lemmatization_result = []\n",
    "\n",
    "for i in range(len(train_data)):\n",
    "    tweet = lemmatizer.lemmatize(train_data['tweet'][i])\n",
    "    lemmatization_result.append(tweet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenization and Stemming with normalization of Uppercase words to Lowercase.\n",
    "\n",
    "Goal is to reduce the vocabulary to the absolutely necessary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import re\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "ps = PorterStemmer()\n",
    "corpus = []\n",
    "\n",
    "for i in range(len(lemmatization_result)):\n",
    "    # get review and remove non alpha chars\n",
    "    tweet = re.sub('[^\\w_\\w]', ' ', lemmatization_result[i])\n",
    "    # to lower-case and tokenize\n",
    "    tweet = tweet.lower().split()\n",
    "    # stemming and stop word removal\n",
    "    tweet = ' '.join([ps.stem(w) for w in tweet if not w in set(stopwords.words('english'))])\n",
    "    corpus.append(tweet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* After the Pre Processing pipeline the vocabulary usefull was reduce to 7588 words a decrese of 50%. This decrease will be usefull to boost the performance of the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_dummy_vectorizer=TfidfVectorizer()\n",
    "_dummy_vectorizer.fit_transform(corpus).toarray()\n",
    "\n",
    "print(len(_dummy_vectorizer.vocabulary_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The  Vocabulary Dillema\n",
    "\n",
    "The perfomance of the algorithms is dependent of the size of the vocabulary. From the analysis we found the optimum value is 800 words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "xpoints = numpy.array([1,10,100,200,500,600,700,800,900,1000,2000,3000,4000,5000,6000,7588])\n",
    "ypoints = numpy.array([0.395, 0.61,0.61,0.61,0.61,0.62,0.60,0.64,0.61,0.62,0.49,0.49,0.46,0.48,0.50,0.49])\n",
    "\n",
    "plt.plot(xpoints, ypoints)\n",
    "plt.xlabel(\"Number of Words\")\n",
    "plt.ylabel(\"Performance of Naive Bayes\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def refresh_data():\n",
    "    vectorizer = TfidfVectorizer(max_features = 800)\n",
    "\n",
    "    X_train=vectorizer.fit_transform(corpus).toarray()\n",
    "    y_train=train_data['label'].copy()\n",
    "    \n",
    "    X_test=vectorizer.transform(test_data['tweet']).toarray()\n",
    "    y_test=test_data['label']\n",
    "    \n",
    "    return (X_train,y_train,X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_stats():\n",
    "    \n",
    "    print(classification_report(y_test,y_predicted))\n",
    "    print(confusion_matrix(y_test, y_predicted))\n",
    "    accuracy_value=accuracy_score(y_test,y_predicted)\n",
    "    precision_value=precision_score(y_test,y_predicted,average='weighted')\n",
    "    f1_value=f1_score(y_test,y_predicted,average='weighted')\n",
    "\n",
    "    actual_conclusion=pandas.DataFrame(\n",
    "        {\n",
    "        'Our Results':[accuracy_value,precision_value,f1_value],\n",
    "        'Winners Result':[0.7347,0.6304,0.8006]\n",
    "        } , index=['Accuracy','Precision','F1-Value'])\n",
    "\n",
    "    print(actual_conclusion.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier=GaussianNB()\n",
    "\n",
    "X_train,y_train,X_test,y_test=refresh_data()\n",
    "\n",
    "classifier.fit(X_train,y_train)\n",
    "\n",
    "y_predicted=classifier.predict(X_test)\n",
    "\n",
    "print_stats()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Neural Network\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "\n",
    "X_train,y_train,X_test,y_test=refresh_data()\n",
    "\n",
    "scaler = StandardScaler()\n",
    "classificator = MLPClassifier(max_iter=1500,activation='relu',solver='adam')\n",
    "\n",
    "scaler.fit(X_train)\n",
    "\n",
    "X_test=vectorizer.transform(test_data['tweet']).toarray()\n",
    "\n",
    "\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "y_test=test_data['label']\n",
    "\n",
    "\n",
    "classificator.fit(X_train, y_train)\n",
    "y_predicted = classificator.predict(X_test)\n",
    "\n",
    "print_stats()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decision Tree\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "X_train,y_train,X_test,y_test=refresh_data()\n",
    "\n",
    "classifier = DecisionTreeClassifier()\n",
    "classifier.fit(X_train, y_train)\n",
    "y_predicted = classifier.predict(X_test)\n",
    "\n",
    "print_stats()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### K-Nearest Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KNN\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "X_train,y_train,X_test,y_test=refresh_data()\n",
    "\n",
    "classifier = KNeighborsClassifier()\n",
    "classifier.fit(X_train, y_train)\n",
    "y_predicted = classifier.predict(X_test)\n",
    "\n",
    "print_stats()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "X_train,y_train,X_test,y_test=refresh_data()\n",
    "\n",
    "classifier = SVC()\n",
    "classifier.fit(X_train, y_train)\n",
    "y_predicted=classifier.predict(X_test)\n",
    "\n",
    "print_stats()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "X_train,y_train,X_test,y_test=refresh_data()\n",
    "\n",
    "classifier = RandomForestClassifier()\n",
    "classifier.fit(X_train, y_train)\n",
    "y_predicted = classifier.predict(X_test)\n",
    "\n",
    "print_stats()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusions For Task 1:\n",
    "\n",
    "TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2 - Different Types of Irony\n",
    "\n",
    "Visit the notebook clicking [here](notebook2.ipynb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
